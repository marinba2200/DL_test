{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN筆記.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marinba2200/DL_test/blob/main/CNN%E7%AD%86%E8%A8%98.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "frHADnl-B9xU"
      },
      "source": [
        "### LeNet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ex-TBPkcCBSf"
      },
      "source": [
        "用的是average pooling，設計方式為維度為小深度越深。\n",
        "\n",
        "其實就是ANN架構，總共參數為60000。\n",
        "\n",
        "Moodle上有做比較的paper(2018/2017)比較計算量與效能。\n",
        "\n",
        "filter size與con的input相同，所以運算下去就會變成1x1的，所以雖然看起來像全連接層，但其實不是。\n",
        "\n",
        "使用pooling調整維度(但不會動到channel，channel是透過conv在調整)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j67jhKa6B5D6"
      },
      "source": [
        "### AlexNet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZeIN8WfCuLS"
      },
      "source": [
        "開始使用ReLU。\n",
        "\n",
        "將網路分成兩個(因為開始用gpu，為了gpu才分割運算量與不分割是相同的)，參數量為60,000,000。(LeNet的1000倍)\n",
        "\n",
        "conv後 = (n+2p-f)/s + 1 (之後無條件捨去)\n",
        "\n",
        "pooling後 = (n-f)/s + 1 (之後無條件進入)\n",
        "\n",
        "使用pooling調整維度(但不會動到channel，channel是透過conv在調整)\n",
        "\n",
        "如果output跟想要的布一樣，可以設定不要預設的最後一層(Dense)，自己再新增想要的Dense。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-F0hh6VDaXX"
      },
      "source": [
        "### VGG-16"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-E1zedYFb_p"
      },
      "source": [
        "很多人在閱讀paper的，比較多人用16，因為效能跟19差不多，計算量較少。\n",
        "\n",
        "pooling不改變厚度，改變size(跟前幾個一樣)。\n",
        "\n",
        "參數量有138,000,000。\n",
        "\n",
        "投影片ImageNet那頁可以看到不同版本效能。\n",
        "\n",
        "Residual Block:\n",
        "\n",
        "VGG再更深層的網路上會比較吃虧，因為加深網路後錯誤反而可能會增加，我們通常希望加深網路後如果錯誤沒有降低，至少也不要比原本更糟。(因為梯度會消失，可能input data解析度太差(資料量會變少))\n",
        "\n",
        "改善辦法：如果網路更身後比較差，就在網路上建立一個捷徑(截斷網路，讓a(l+2)變成a(l))，讓較淺的網路(截斷後的網路)取代加深後劣化的網路。\n",
        "\n",
        "這個改善辦法在ResNet可以看到。\n",
        "\n",
        "a(l+2)=g(W(l+2)a(l+1)+b(l+2)+a(l)) => 使W跟b趨近於0 => a(l+2)→a(l)\n",
        "\n",
        "ResNet架構中截斷符號有虛線實線，虛線代表截斷前後維度不同(需要加入一個轉換維度的矩陣Ws)。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Id6infnADaUT"
      },
      "source": [
        "### GoogleNet(Inception)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mnjt1mQ5DaRS"
      },
      "source": [
        "input進入後會同時做：conv(1x1),conv(3x3),conv(5x5),pooling(3x3)。\n",
        "\n",
        "做好的ouput 會有4個，全部疊在一起(當要把output疊在一起，維度就很重要，pooling可以用步伐去控制讓output不要縮size的維，用conv(1x1)調整channel)。\n",
        "\n",
        "計算量會非常大，這個時候可以先做縮為度的動作再增維度(用conv(1x1))\n",
        "\n",
        "所以GoogleNet 架構其實是： conv(1x1) , conv(1x1) x conv(3x3) , conv(1x1) x conv(5x5) , pooling(3x3) x conv(1x1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mqZM5RvADaOY"
      },
      "source": [
        "### ResNet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4em3tlBeUgRE"
      },
      "source": [
        "VGG-16後面有提到"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_0EEHRAOTmu"
      },
      "source": [
        "### 集成式學習(借用權重)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pxJdNv1-DZ9z"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "不一定大家都有設備跟時間可以訓練網路，所以可以去公用平台使用其他人訓練好的類似(例如都是要訓練車子，那麼他的權重也可能會跟你的類似)目的網路來再訓練成自己想要的。\n",
        "\n",
        "import對方的網路架構與權重後就固定住對方的部分網路，仰賴對方特徵提取的功能後再做修正與訓練(Layer就不用太高)。\n",
        "\n",
        "對方的網路input X ,我們可以將對方的output(y')當作我們的X。(data多的時候我們固定對方網路架構的部分可以多一點(花的時間會較久))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cCFKNmW5Pygr"
      },
      "source": [
        "### 擴增資料"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJTUi-8cP1p2"
      },
      "source": [
        "1. 可以局部剪取目標照片(使目標偏移(小心不要太邊緣))，或是飄倍(色系變暖變冷)。\n",
        "2. 做集成式學習(例如隨機森林)。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4KQ85RCpfNOO"
      },
      "source": [
        "### YOLO (物件偵測)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2e0jViDJfP7E"
      },
      "source": [
        "重複抓到的資料=>計算每個框框的物件的機率,會先mark最大機率的框框，在計算被mark的框框跟其他的IOU(重疊率)，IOU值高過一個閥值的就請他離開。\n",
        "\n",
        "可能發生大框框框的是物件1，但是物件2被包含在大框框內，這樣偵測到物件2的小框框就會不小心完全重疊大框框=>最後的y可以將不同類別(長寬比不同的)物件另外做label串接在一起變成新的y。\n",
        "\n",
        "例如一種物件會用掉8個label(最後的y矩陣中)，如果會偵測5種物件，最後的一個維度就會變成8*5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddxsiDA5Za1O"
      },
      "source": [
        "bx,by惠介於01之間，因為只是一點。但bh,bw會很容易超過1，因為物件面積很少會只有一個pixel。\r\n",
        "\r\n"
      ]
    }
  ]
}